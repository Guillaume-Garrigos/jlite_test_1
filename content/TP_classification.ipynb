{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TP : Mod√©lisation et r√©solution d'un probl√®me de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions g√©n√©rales:**\n",
    "\n",
    "- Je vous conseille de r√©aliser ce devoir avec `jupyter lab` et non pas `jupyter notebook`. La raison est que `jupyter notebook` a parfois du mal √† afficher des images.\n",
    "- Les d√©pendances n√©cessaires sont incluses dans le fichier `requirements.txt`.\n",
    "- Le devoir vous a √©t√© distribu√© sous la forme d'un dossier contenant un notebook et d'autres fichiers. Vous pouvez d√©placer le dossier o√π vous voulez dans votre ordinateur, mais ne changez pas la structure de ce dossier : le notebook a besoin de ces fichiers auxiliaires pour fonctionner!\n",
    "- Certaines questions n√©cessitent de faire tourner un algorithme. Je vous recommande de ne pas faire tourner vos algorithmes plus qu'une trentaine de secondes (chez moi tout marche bien en moins d'une seconde)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description du devoir:**\n",
    "\n",
    "- la partie **I** est une mise en bouche avec le probl√®me.\n",
    "- la partie **II** porte sur un probl√®me-jouet, et est celle o√π vous mettrez en valeur certaines des choses que vous avez appris en cours. Elle se d√©compose en trois sections **ind√©pendantes**, qui proposent de r√©soudre le probl√®me de trois mani√®res diff√©rentes. Elles peuvent √™tre trait√©es √† des moments diff√©rents du cours:\n",
    "  - la partie **II.A** ne requiert aucune connaissance particuli√®re du cours. Si vous voulez simplement vous amuser avec le sujet c'est par l√†!\n",
    "  - la partie **II.B** porte sur la dualit√© de Rockafellar (fin du chapitre 2). Elle vous demandera de faire des petits calculs de dualit√© √† la main. C'est l'occasion de voir si vous avez compris les bases de ce chapitre!\n",
    "  - la partie **II.C** porte sur les m√©thodes d'√©clatement, et n√©c√©ssite d'avoir vu la notion d'op√©rateur proximal (d√©but du chapitre 3).\n",
    "- la partie **III** est une application √† un probl√®me de traitement de donn√©es, qui consiste √† exploiter les r√©sultats de la partie **II** sur un vrai probl√®me. C'est l√† que vous montrerez si vous avez compris ce qui se passe dans la partie **II**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cette cellule importe les modules n√©c√©ssaires √† ce TP. En cas d'erreur, vous devrez au pr√©alable installer les modules manquants.\n",
    "# Lors d'une premi√®re ex√©cution cela peut prendre un peu de temps, jusqu'√† 1 min parfois :(\n",
    "import numpy\n",
    "import matplotlib\n",
    "import scipy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vous invite pour commencer √† aller lire la section **\"Mod√©lisation : classification\"** qui se trouve en annexe du [polycopi√©](https://cloud.math.univ-paris-diderot.fr/s/fLXPipwgSC9tpzj) du cours. Il y est d√©crit ce qu'est un probl√®me de classification, et comment le mod√©liser math√©matiquement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Premier contact avec le probl√®me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** On commence par importer des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data/donnees_entrainement.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces donn√©es correspondent √† $m$ points de $\\mathbb{R}^2$, qui sont rang√©es dans une matrice √† $m$ lignes et 2 colonnes.\n",
    "Chaque *ligne* de la matrice correspond donc √† un point de $\\mathbb{R}^2$.\n",
    "Vous pouvez regarder quelle est la taille de la matrice avec la m√©thode `X.shape`, ce qui vous permettra de d√©terminer la valuer de $m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 200 # √† definir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vu que nos donn√©es sont des points du plan, on va pouvoir facilement les visualiser avec la fonction `plt.scatter` de pyplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couleur = [None]*m # liste vide de taille m\n",
    "for k in range(m):\n",
    "    couleur[k] = 'blue'\n",
    "_=plt.scatter(X[:, 0], X[:, 1], c=couleur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Vous devriez √™tre maintenant convaincus que ce jeu de donn√©es contient deux groupes de points appartenant √† des familles distinctes. Or nous n'en savons rien, √† priori, le seul moyen d'en √™tre sur est d'aller regarder les *etiquettes* correspondantes. Importons-les:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.load('data/etiquettes_entrainement.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V√©rifiez que ce vecteur ne contient que des √©tiquettes $\\pm 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En adaptant le code de la pr√©c√©dente question, affichez de nouveau ce nuage de points cette fois-ci avec deux couleurs: rouge pour les points avec l'√©tiquette $-1$, et bleu pour les points avec l'√©tiquette $+1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couleur = [None]*m\n",
    "for k in range(m):\n",
    "    if Y[k] == 1:\n",
    "        couleur[k] = 'blue'\n",
    "    else:\n",
    "        couleur[k] = 'red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.scatter(X[:, 0], X[:, 1], c=couleur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Une approche intuitive pour classer ce probl√®me consiste √† tracer une droite qui va s√©parer ces deux nuages: ainsi fait, on pourra dire que tout nouveau point qui apparaitra d'un c√¥t√© de la droite sera \"rouge\" et de l'autre les \"bleus\".\n",
    "\n",
    "Ici on va consid√©rer une droite dans $\\mathbb{R}^2$ comme √©tant l'ensemble des points satisfaisant l'√©quation\n",
    "\n",
    "$$ D = \\{ x \\in \\mathbb{R}^2 \\ | \\ \\langle a, x \\rangle = b \\},$$\n",
    "\n",
    "o√π $a \\in \\mathbb{R}^2$ et $b \\in \\mathbb{R}$ sont √† choisir. On notera par la suite $w = (a_1, a_2 ,b) \\in \\mathbb{R}^2 \\times \\mathbb{R}$ le vecteur de param√®tres d√©crivant la droite $D$.\n",
    "\n",
    "En utilisant le code ci-dessous, ajoutez le trac√© d'une droite aux donn√©es, et jouez avec la valeur de $w$ pour essayer de trouver la droite qui s√©pare le mieux les deux classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_droite(w):\n",
    "    # trace la droite des points x v√©rfiant l'√©quation <a,x>=b\n",
    "    # o√π w = (a_1, a_2, b)\n",
    "    # on va la tracer comme la droite alpha * t + b\n",
    "    a = w[0:2]\n",
    "    b = w[2]\n",
    "    if a[1] == 0:\n",
    "        if a[0] != 0:\n",
    "            # on a une droite verticale\n",
    "            x = b/a[0]\n",
    "            plt.axvline(x=x)\n",
    "        else: \n",
    "            return\n",
    "            # a=0 donc cela ne d√©finit pas une droite, on ne trace rien\n",
    "    else:\n",
    "        alpha = -a[0]/a[1]\n",
    "        beta = b/a[1]\n",
    "        abscisse = np.arange(-5,5,0.1)\n",
    "        ordonnee = alpha*abscisse + beta\n",
    "        plt.plot(abscisse, ordonnee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([0, 1, 0]) # √† modifier\n",
    "trace_droite(w)\n",
    "_=plt.scatter(X[:, 0], X[:, 1], c=couleur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pensez-vous que certaines droites sont meilleures que les autres?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Mod√©lisation : trouver une droite s√©paratrice optimale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vous invite si ce n'est toujours pas fait √† aller lire la section **\"Mod√©lisation : classification\"** qui se trouve en annexe du [polycopi√©](https://cloud.math.univ-paris-diderot.fr/s/fLXPipwgSC9tpzj) du cours.\n",
    "Il y est expliqu√© comment faire pour trouver un hyperplan qui s√©pare bien des donn√©es dans $\\mathbb{R}^n$, et plus pr√©cis√©ment comment trouver le *meilleur* hyperplan s√©parateur possible (en un certain sens).\n",
    "\n",
    "Plus pr√©cis√©ment, consid√©rons le probl√®me de s√©parer $m$ points $x_i \\in \\mathbb{R}^n$ avec √©tiquettes $y_i \\in \\{\\pm 1\\}$.\n",
    "Alors on peut montrer que le meilleur hyperplan s√©parateur est d√©fini par\n",
    "\n",
    "$$ \\mathcal{H}_w := \\{ x \\in \\mathbb{R}^n \\ | \\ \\langle a,x \\rangle = b \\}, \\quad w=(a,b) \\in \\mathbb{R}^n \\times \\mathbb{R},$$\n",
    "\n",
    "o√π $w=(a,b) \\in \\mathbb{R}^n \\times \\mathbb{R}$ est la solution du probl√®me d'optimisation quadratique convexe suivant (appel√© SVM) : \n",
    "\\begin{equation}\n",
    "    \\min\\limits_{w \\in \\mathbb{R}^{n} \\times \\mathbb{R}} \\ \\frac{1}{2} \\Vert Pw \\Vert^2 \n",
    "    \\quad \n",
    "    \\text{ sous la contrainte que } \\Phi w \\preceq -e,\n",
    "    \\tag{P}\n",
    "\\end{equation}\n",
    "o√π \n",
    "\n",
    "- $e:=(1,\\dots,1)^\\top \\in \\mathbb{R}^m$ \n",
    "- $P \\in \\mathcal{M}_{n+1}(\\mathbb{R})$ est la matrice de projection sur $F = \\{ w \\in \\mathbb{R}^{n+1} \\ | \\ w_{n+1}=0\\}$. Autrement dit $P$ projette sur les $n$ premi√®res coordonn√©es. On se convainc que $P= {\\rm{diag}}(1, \\dots, 1, 0)$.\n",
    "- $\\Phi \\in \\mathcal{M}_{m,n+1}(\\mathbb{R})$ est la matrice d√©finie par\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\Phi :=\n",
    "    \\begin{pmatrix}\n",
    "        -y_1 x_1^\\top & y_1 \\\\\n",
    "        \\vdots & \\vdots \\\\\n",
    "        -y_i x_i^\\top & y_i \\\\\n",
    "        \\vdots & \\vdots \\\\\n",
    "        -y_m x_m^\\top & y_m\n",
    "    \\end{pmatrix}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# II. R√©solution du probl√®me : phase d'entra√Ænement\n",
    "\n",
    "Dans cette partie, nous allons r√©soudre le probl√®me (P) de trois mani√®res diff√©rentes, dans les sections A,B et C.\n",
    "Ces trois sections sont de difficult√© variable, mais ind√©pendantes:\n",
    "\n",
    "- la section A ne requiert aucun pr√©requis\n",
    "- la section B requiert d'avoir vu la dualit√© de Fenchel-Rockafellar. Elle contient notamment des petits exercices que vous √™tes encourag√©s √† faire.\n",
    "- la section C requiert d'avoir vu la notion d'op√©rateur proximal. Elle applique un algorithme vu dans le dernier chapitre du cours.\n",
    "\n",
    "Le but est d'√©crire du code pour des donn√©es qui vivent en dimension $n$, et de les appliquer dans un premier temps √† nos nuages de points pour lesquels $n=2$.\n",
    "Dans la partie suivante nous appliquerons ce code √† un vrai probl√®me plus int√©ressant, pour lequel $n >> 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0)** On d√©finit `e`, le vecteur $e:=(1,\\dots,1)^\\top \\in \\mathbb{R}^m$, ainsi que `Phi`, la matrice $\\Phi \\in \\mathcal{M}_{m,3}(\\mathbb{R})$ d√©finie dans la section pr√©c√©dente. On rappelle que cette matrice ne d√©pend que de `X` et `Y`.\n",
    "\n",
    "On d√©finira √©galement `infini`, le vecteur $(+\\infty, \\dots, +\\infty) \\in \\mathbb{R}^m$, sachant que la quantit√© $+\\infty$ s'obtient avec `np.inf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=np.ones(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi = np.zeros((m,3)) # matrice vide\n",
    "Phi[:, 0:-1] = -X # toutes les colonnes sauf une remplies par -X\n",
    "Phi[:, -1] = e # derni√®re colonne remplie par des 1\n",
    "Phi = np.diag(Y)@Phi # on multiplie chaque ligne par y_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infini = e*np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A. R√©solution via un solveur Python\n",
    "\n",
    "Ici nous allons simplement donner le probl√®me √† Python, qui dispose de certaines routines pour r√©soudre les probl√®mes d'optimisation. Toute la difficult√© consiste en la mise en forme du probl√®me dans une syntaxe que Python peut comprendre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** D√©finir une fonction `objectif` qui prend en entr√©e un vecteur $w=(a,b) \\in \\mathbb{R}^n \\times \\mathbb{R}$ et qui renvoie $\\Vert a \\Vert^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** On doit r√©soudre un probl√®me d'optimisation sous contrainte. Pour cela, on va faire appel √† la biblioth√®que `scipy.optimize` qui peut faire cela pour nous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import LinearConstraint, minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord on doit d√©finir la contrainte $\\Phi w \\preceq -e$. Il faut pour cela utiliser la fonction `LinearConstraint` qui permet de d√©finir une contrainte de la forme\n",
    "$$\n",
    "\\{ w \\in \\mathbb{R}^d \\ | \\ a \\preceq \\Phi w \\preceq b \\}\n",
    "$$\n",
    "avec la commande `LinearConstraint(Phi, a, b)` (voir la [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.LinearConstraint.html#scipy.optimize.LinearConstraint) pour plus de d√©tails). A vous de compl√©ter la commande suivante, avec les objets d√©finis √† la question **1)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrainte = LinearConstraint(############)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** On peut maintenant obtenir la solution de notre probl√®me, en faisant appel √† `scipy.optimize.minimize` (voir la [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) pour plus de d√©tails)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sol_scipy = minimize(                          # minimiser\n",
    "                    fun = objectif,           # la fonction 'objectif'\n",
    "                    constraints = contrainte, # sous la contrainte 'contrainte'\n",
    "                    x0 = np.random.randn(3),  # en partant d'un point initial\n",
    "                    ).x                       # et donne-moi le vecteur solution\n",
    "w_sol_scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Reprendre le code de la partie **I.1**, pour afficher les nuages de points ainsi que la droite d√©finie par le param√®tre $w_{sol-scipy} \\in \\mathbb{R}^3$ que vous venez d'obtenir. √ätes-vous satisfait(e) de la solution obtenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_droite(w_sol_scipy)\n",
    "_=plt.scatter(X[:, 0], X[:, 1], c=couleur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## B. R√©solution via le probl√®me dual et la m√©thode du gradient projet√©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous allons nous int√©r√©sser √† (D), le probl√®me dual de (P) au sens de Fenchel-Rockafellar. Dans un premier temps nous allons calculer ce probl√®me dual. Dans un second temps, nous allons voir qu'il a une structure plus simple, le rendant facile √† r√©soudre.\n",
    "Dans un troisi√®me temps, nous allons r√©soudre (D) avec la m√©thode du gradient projet√©, puis retrouver une solution du probl√®me primal (P)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Calcul du probl√®me dual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** üìù Montrer que le probl√®me (P) peut s'√©crire sous la forme \n",
    "\\begin{equation*}\n",
    "    \\min\\limits_{w \\in \\mathbb{R}^{n+1}} \\ f(w) + g(\\Phi w), \n",
    "    \\tag{P}\n",
    "\\end{equation*}\n",
    "o√π\n",
    "- $f$ est une fonction quadratique semi d√©finie positive,\n",
    "- $g = \\delta_C$ est la fonction indicatrice de $C$, un ensemble convexe ferm√© non vide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** üìù D'apr√®s la dualit√© de Fenchel-Rockafellar, le probl√®me dual de (P) consiste √† r√©soudre\n",
    "\\begin{equation*}\n",
    "    \\min\\limits_{u \\in \\mathbb{R}^m} \\ f^* (-\\Phi^\\top u) + g^* (u), \n",
    "    \\tag{D}\n",
    "\\end{equation*}\n",
    "Vous devrez:\n",
    "\n",
    "- Calculer la conjugu√©e de Fenchel $f^*$. Pour cela vous pourrez utiliser un r√©sultat de la feuille de TD sur la conjugu√©e.\n",
    "- Calculer la conjugu√©e de Fenchel $g^*$. Vous utiliserez des r√©sultats du cours  pour montrer que \n",
    "\\begin{equation*}\n",
    "    g^*(u) = \\delta_K(u) - \\langle e, u \\rangle,\n",
    "\\end{equation*}\n",
    "o√π $K$ est un c√¥ne convexe ferm√© (tr√®s sympatique) non vide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** üìù Conclure que le probl√®me dual s'√©crit\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\min\\limits_{u \\in \\mathbb{R}^M} \\ h(u), \n",
    "    \\quad \n",
    "    \\text{ sous la contrainte que } u \\in K \\text{ et } \\langle y,u \\rangle =0,\n",
    "    \\tag{D}\n",
    "\\end{equation*}\n",
    "o√π $h$ est une fonction convexe quadratique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. D√©finition de la projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ici on s'int√©resse √† la projection sur la contrainte duale\n",
    "$$D:= \\{ u \\in \\mathbb{R}^M \\ | \\ u \\in K \\text{ et } \\langle y,u \\rangle =0\\},$$\n",
    "o√π $K$ est le c√¥ne simple que vous avez obtenu √† la section pr√©c√©dente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** On va ici impl√©menter une alternative √† la m√©thode de projection approch√©e de la question pr√©c√©dente avec la **projection de Kiwiel**. Cette derni√®re s'effectue avec la fonction `proj_kiwiel` (import√©e ci-dessous), qui:\n",
    "\n",
    "- projette un vecteur $u$ sur une intersection $K \\cap H$ \n",
    "   - o√π $H$ est un hyperplan $H = \\{ u \\in \\mathbb{R}^M \\ | \\ \\langle y, u \\rangle =0 \\}$\n",
    "   - o√π $K$ est un ensemble d√©fini par $K = \\{ u \\in \\mathbb{R}^M \\ | \\ a \\preceq u \\preceq b \\}$\n",
    "     - ici les bornes $a, b \\in \\mathbb{R}^M$ peuvent prendre des valeurs $\\pm \\infty$\n",
    "- prend en entr√©e `proj_kiwiel(u, y, a, b)` o√π $u$ est le vecteur √† projeter, $y$ le vecteur d√©finissant l'hyperplan $H$, et $a,b$ sont les bornes (inf√©rieures et sup√©rieures) d√©finissant $K$.\n",
    "- renvoie en sortie la projection de $u$ sur $K \\cap H$.\n",
    "\n",
    "Votre travail ici consiste √† d√©finir une fonction `proj_D` qui prend en entr√©e un vecteur `u`, le vecteur `y`, et renvoie la projection de $u$ sur $D$.\n",
    "Pour ce faire, vous d√©finirez les bornes `a` et `b` qui d√©finissent $K$, et vous appliquerez la projection de Kiwiel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.kiwiel import proj_kiwiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_D(u, y):\n",
    "    # ########  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) BONUS:** Dans cette question totalement facultative, on vous propose de coder vous-m√™me une projection sur $K \\cap H$ en utilisant les algorithmes vus en cours. \n",
    "En effet, on peut √©crire\n",
    "\n",
    "$$ proj_{K \\cap H}(x) = {\\rm{argmin}}_y  \\frac{1}{2} \\Vert y - x \\Vert^2 + \\delta_K(y) + \\delta_H(y).$$\n",
    "\n",
    "Il s'agit donc de r√©soudre un probl√®me de minimisation de la forme $f + g$ o√π $f(y) = \\frac{1}{2} \\Vert y - x \\Vert^2 + \\delta_K(y)$ et $g(y) = \\delta_H(y)$.\n",
    "Ce type de probl√®me peut se r√©soudre avec l'algorithme de Douglas-Rachford, qui dans ce cas particulier devient (avec un peu de travail) la m√©thode de **projection de Dijkstra**:\n",
    "Elle se d√©finit via des projections altern√©es sur $H$ et $K$, comme suit:\n",
    "\n",
    "| Projection de Dijkstra |\n",
    "|-|\n",
    "| On veut projeter $u$ sur $K\\cap H$ |\n",
    "| On initialise $x_0=u$, et $h_0=p_0=q_0=0$, puis pour $k \\geq 0$: | \n",
    "| $$\\begin{cases} h_{k+1} & =  {\\rm{proj}}_H(x_k+p_k) \\\\ p_{k+1} &= x_k + p_k - h_{k+1} \\\\ x_{k+1} &= {\\rm{proj}}_K( h_{k+1} + q_k) \\\\ q_{k+1} &= h_{k+1} + q_k - x_{k+1} \\end{cases}$$ |\n",
    "| **Th√©or√®me:** $x_k \\to {\\rm{proj}}_{K\\cap H}(u)$ lorsque $k \\to +\\infty$ | \n",
    "\n",
    "Nous vous proposer de coder la projection sur $K$ et $H$ (qui sont relativement faciles), puis de calculer une dizaine d'it√©rations de la projection de Dijkstra. Vous pourrez alors comparer votre r√©sultat avec la projection de Kiwiel (en projetant un vecteur al√©atoire par exemple), et avoir le plaisir d'avoir calcul√© cette projection vous-m√™me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. M√©thode du gradient projet√©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La m√©thode du gradient projet√© permet de r√©soudre un probl√®me de la forme \n",
    "$$ \\min f(x), x \\in C$$\n",
    "L'algorithme s'√©crit \n",
    "\n",
    "| | | |\n",
    "|-|-|-|\n",
    "|| On choisit $x_0$ un vecteur de $\\mathbb{R}^N$ et $\\rho > 0$ un pas fixe. | \n",
    "|  | Pour $k\\geq 0$ : $\\qquad \\qquad \\, $   $x_{k+1}$  = ${\\rm{proj}}_C(x_k - \\rho \\nabla f(x_k))$  | \n",
    "\n",
    "L'algorithme est garanti de converger si $f$ est convexe, de classe $C^1$, avec un gradient $L$-Lipschitzien, et un pas $\\rho \\in ]0,2/L[$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** üìù V√©rifier que les hypoth√®ses ci-dessus sont v√©rifi√©es pour le probl√®me dual (D). En particulier, vous calculerez $\\nabla h$, et vous d√©finirez sa constante de Lipschitz `L`.\n",
    "On rappelle que la norme d'op√©rateur d'une matrice `A` s'obtient avec `np.linalg.norm(A,2)` ; et que la constante de Lipschitz de $\\nabla f$ est la borne sup√©rieure de $\\Vert \\nabla^2 f(x) \\Vert$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** D√©finir une fonction `FB_dual` qui r√©soud le probl√®me dual (D) en:\n",
    "\n",
    "- prenant en entr√©e la matrice `Phi`, le vecteur `y`, un pas `rho`, un nombre d'it√©rations `nb_iter`\n",
    "- r√©solvant le probl√®me dual en appliquant la m√©thode du gradient projet√© :\n",
    "  - en initialisant les it√©r√©s en $0 \\in \\mathbb{R}^m$\n",
    "  - avec un pas `rho`\n",
    "  - en r√©alisant la projection sur $D$ avec une fonction d√©finie dans la section pr√©c√©dente (de votre choix)\n",
    "  - pendant un nombre d'it√©rations √©gal √† `nb_iter`\n",
    "- retournant en sortie le dernier it√©r√© calcul√© "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FB_dual(Phi, y, rho, nb_iter=500):\n",
    "    # #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Trouver `u_sol_GPD` une solution approch√©e au probl√®me dual (D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** üìù D'apr√®s la caract√©risation des solutions du probl√®me primal-dual vu en cours, on sait que la solution $w$ du probl√®me primal est li√©e √† la solution $u$ du probl√®me dual via l'inclusion $w \\in \\partial f^*(-\\Phi^\\top u)$.\n",
    "Montrer que ceci implique que $-\\Phi^\\top u$ peut s'√©crire   $-\\Phi^\\top u= (a,0)$ o√π $a \\in \\mathbb{R}^n$, et que $w=(a,b)$ pour un certain $b$ √† d√©terminer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**5)** Vous v√©rifierez num√©riquement que la derni√®re coordonn√©e de $\\Phi^\\top u$ est bien nulle. D√©finissez `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** On admet par la suite que l'on peut prendre $b=0$, c-√†-d que $w = -\\Phi^\\top u$ est solution de notre probl√®me primal (P). Reprendre le code de la partie **I.1**, pour afficher les nuages de points ainsi que la droite d√©finie par le param√®tre $w \\in \\mathbb{R}^3$ que vous venez d'obtenir. √ätes-vous satisfait(e) de la solution obtenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. R√©solution via une m√©thode d'√©clatement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, l'objectif est que vous soyez plus autonomes. Nous vous fournissons un algorithme, un th√©or√®me, et vous devez vous en servir pour trouver une solution aux probl√®mes (P) et (D). A vous de v√©rifier que votre code fonctionne et vous fournit une solution satisfaisante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On introduit l'algorithme de **Loris-Verhoeven**, qui est une g√©n√©ralisation de la m√©thode du gradient proximal, et un cas particulier de l'algorithme de Yan, qui s'applique √† la minimisation d'une fonction de la forme $g(Ax) + h(x)$, o√π $g \\in \\Gamma_0(\\mathbb{R}^M)$ et $h \\in \\Gamma_0(\\mathbb{R}^N) \\cap C^{1,1}_L(\\mathbb{R}^N)$:\n",
    "\n",
    "| L'algorithme de **Loris-Verhoeven** |\n",
    "| --- |\n",
    "| Soient $x_0 \\in \\mathbb{R}^N, u \\in \\mathbb{R}^M$, $\\lambda, \\sigma >0$ |\n",
    "| $$\\begin{cases} x_{k+1} &= x_k - \\lambda \\nabla h(x_k) - \\lambda A^\\top u_n \\\\ u_{k+1} &=  {\\rm prox}_{{\\sigma}g^*} \\left(u_n + \\sigma A \\left[2x_{k+1} - x_k + \\lambda \\nabla h(x_k) - \\lambda \\nabla h(x_{k+1}) \\right]\\right) \\end{cases}$$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Th√©or√®me:** Soient $h : \\mathbb{R}^n \\to \\mathbb{R}$ une fonction diff√©rentiable √† gradient $L$-Lipschitzien,  $g : \\mathbb{R}^m \\to \\mathbb{R}\\cup\\{+\\infty\\}$ une fonction convexe s.c.i. propre, et $A \\in \\mathcal{M}_{m,n}(\\mathbb{R})$.\n",
    "Soit $(x_k,u_k)_{k \\in \\mathbb{N}}$ une suite g√©n√©r√©e par l'algorithme de Loris-Verhoeven, avec\n",
    "$$ \\lambda \\in \\left]0, \\frac{2}{L}\\right[ \\quad \\text{ et } \\quad \\sigma \\in \\left]0, \\frac{1}{\\lambda \\Vert A \\Vert^2}\\right].$$\n",
    "Alors \n",
    "- $x_k$ converge vers un minimiseur de $f + g \\circ A$, s'il en existe,\n",
    "- $u_k$ converge vers un minimiseur de $f^* \\circ -A^\\top + g^*$ s'il en existe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer les trois solutions obtenues. D'une part vous visualiserez les 3 droites s√©paratrices correspondantes. Ensuite vous √©valuerez $f$ en ces points. Donner votre avis sur vos r√©sultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# III. Classifier des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Obtention des donn√©es : Importer le jeu de donn√©es MNIST\n",
    "\n",
    "On va r√©soudre un probl√®me similaire, sauf que cette fois les donn√©es ne sont plus des points $x_i \\in \\mathbb{R}^2$ rouges ou bleus, mais des images $x_i \\in \\mathbb{R}^{64}$ de chiffres √©crits √† la main.\n",
    "On ne parlera donc plus de \"droite s√©paratrice\" mais d'\"hyperplan s√©parateur\".\n",
    "\n",
    "| Un nouveau jeu de donn√©es | \n",
    "| ----------- |\n",
    "| ![](images/mnist.jpg) |\n",
    "| Chaque image de $8\\times 8$ pixels est repr√©sent√©e par un point $x_i \\in \\mathbb{R}^{64}$ |\n",
    "\n",
    "Pour ce TP on va se contenter de s√©parer des images de 0 et de 1. Leurs √©tiquettes $y_i$ prendront respectivement les valeurs $-1$ et $+1$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param√®tres pour l'affichage des images de nombres\n",
    "plt.rcParams['xtick.bottom'] = False\n",
    "plt.rcParams['ytick.left'] = False\n",
    "plt.rcParams['xtick.labelbottom'] = False\n",
    "plt.rcParams['ytick.labelleft'] = False\n",
    "plt.rcParams['image.cmap'] = 'gray_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importe les donn√©es\n",
    "digits = sklearn.datasets.load_digits() # Importe un jeu de donn√©es √† classer (10 classes)\n",
    "digits.data = digits.data*1/np.max(digits.data) # normalise : coeffs dans [0,1]\n",
    "classes = [0, 1] # D√©finit les 2 classes de nombres avec lesquelles on va travailler\n",
    "idx_classes = np.logical_or(digits.target == classes[0], digits.target == classes[1]) # Localise les deux classes ..\n",
    "digits.data = digits.data[idx_classes] # .. les extrait ..\n",
    "digits.target = digits.target[idx_classes] # .. et jette le reste\n",
    "digits.target = np.where(digits.target==classes[0],-1, 1) # Transforme les √©tiquettes de classes en {-1,+1}\n",
    "\n",
    "X, X_test, Y, Y_test = sklearn.model_selection.train_test_split( # On coupe le jeu de donn√©es en deux\n",
    "                        digits.data, digits.target, train_size=25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche les 25 premi√®res images de X\n",
    "fig, axs = plt.subplots(5, 5, figsize=(3, 3))\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        k = i*5 + j\n",
    "        _ = axs[i,j].imshow(X[k].reshape(8,8))\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** On dispose de donn√©es `X`, qui contient des images de 0 et 1 √©crits √† la main. Plus pr√©cis√©ment, pour tout `k`, `X[k]` repr√©sente une telle image 2D (8x8 pixels) qui a √©t√© aplatie en un vecteur 1D.\n",
    "\n",
    "Utiliser `.shape` pour d√©terminer le nombre d'images que contient `X`.\n",
    "\n",
    "Prendre une image au hasard, et l'afficher avec la fonction `plt.imshow()`. Afin de l'afficher, vous aurez besoin de temporairement remettre cette image sous forme 2D avec la m√©thode `.reshape(nb_lignes, nb_colonnes)` . Est-ce l'image d'un 0 ou d'un 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[10].reshape(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** On dispose d'√©tiquettes `Y` qui encodent la nature des images contenues dans `X`. Plus pr√©cis√©ment, `Y[k]` contient `-1` si `X[k]` est l'image d'un 0, ou `+1` si `X[k]` est l'image d'un 1.\n",
    "\n",
    "Reconsid√©rer l'image affich√©e √† la question pr√©c√©dente, et v√©rifier que son √©tiquette correspond √† ce que vous avez observ√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Phase d'entra√Ænement : Trouver un classifieur avec la m√©thode SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0)** D√©finir `m` le nombre de donn√©es dans notre jeu de donn√©es ; et `n` la taille de chacune de ces donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "n = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Nous allons trouver un classifieur lin√©aire avec la m√©thode SVM, comme au I.\n",
    "\n",
    "Pour ce faire, d√©finir deux vecteurs `e`$= (1, \\dots , 1)^\\top$, `infini`$=(+\\infty, \\dots, +\\infty)^\\top$ de $\\mathbb{R}^m$, ainsi que la matrice $\\Phi \\in \\mathcal{M}_{m,n+1}(\\mathbb{R})$ d√©finie en Section I.2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.ones(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi = np.zeros((m, n+1)) # matrice vide\n",
    "Phi[:, 0:-1] = -X # toutes les colonnes sauf une remplies par -X\n",
    "Phi[:, -1] = e # derni√®re colonne remplie par des 1\n",
    "Phi = np.diag(Y)@Phi # on multiplie chaque ligne par y_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infini = e*np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Adapter √† partir de la Section **II** la m√©thode de r√©solution de votre choix pour obtenir une solution $w=(a,b) \\in \\mathbb{R}^{n+1}$ du probl√®me de SVM (P). Vous appellerez cette solution `w_mnist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Ecrire une fonction `classifieur`, qui:\n",
    "- prend en entr√©e une image aplatie `x`$\\in \\mathbb{R}^n$\n",
    "- prend en entr√©e un vecteur de param√®tres  `w`$=(a,b)\\in \\mathbb{R}^n \\times \\mathbb{R}$\n",
    "- retourne +1 si $\\langle a, x \\rangle \\geq  b$, -1 si $\\langle a, x \\rangle \\leq b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifieur(x, w):\n",
    "    # ###########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Prendre une image au hasard dans `X`, et comparer sa vraie √©tiquette avec la pr√©diction faite par notre nouveau classifieur. Notre pr√©diction est elle bonne?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Phase de test : connaitre la vraie performance de notre classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vient de voir que notre classifieur marche bien lorsque on l'applique aux images contenues dans `X`. Or ceci n'est pas tr√®s surprenant : le classifieur a √©t√© construit √† partir de `w_mnist`, la solution d'un probl√®me d'optimisation d√©pendant des donn√©es contenues dans `X,Y`. Pour vraiment d√©terminer si notre mod√®le a **appris** quelque chose, il faut le tester sur des donn√©es qu'il n'a encore **jamais vues**.\n",
    "\n",
    "On va donc maintenant utiliser les donn√©es de test `X_test` et `Y_test` que l'on a pas encore utilis√©es."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Calculer le pourcentage de bonnes r√©ponses donn√©es par notre `classifieur`. Autrement dit, vous allez parcourir l'ensemble des donn√©es de test, et calculer le pourcentage du nombre de fois que le classifieur donne la bonne pr√©diction, en la comparant √† la vraie √©tiquette contenue dans `Y_test`. Que pensez-vous du nombre obtenu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Si le taux de bonne r√©ponse n'est pas de 100%, essayez de trouver dans le jeu de donn√©es quelles sont les images sur lesquelles le classifieur se trompe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Si vous retournez au d√©but de la section **III.**, vous pouvez voir qu'au moment de l'importation nous avons demand√© √† travailler avec les `classes` 0 et 1.\n",
    "\n",
    "Remplacez ces chiffres par deux autres chiffres de votre choix, et relancez votre code afin de d√©terminer le taux de bonne r√©ponse du classifieur. Essayez de prendre des chiffres difficiles √† classer!\n",
    "\n",
    "**NB:** Vous ne serez pas not√©s sur cette question, qui vous laisse libre de vous amuser. N√©anmois je vous conseille de ne pas l'ignorer, car vous devrez de toute fa√ßon faire ce genre de choses dans les questions suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Aller plus loin : Classification multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "On a vu comment classer des donn√©es √† deux √©tiquettes. Mais en pratique il y a souvent un plus grand nombre de classes : par exemple MNIST peut contenir jusqu'√† 10 classes: les chiffres de 0 √† 9! Un tel classifieur vous est par exemple mis √† disposition sur [ce site](https://mco-mnist-draw-rwpxka3zaa-ue.a.run.app/), qui vous permet de dessiner en ligne un chiffre et vous fournira en temps r√©el une estimation de la probabilit√© d'appartenance √† une classe de chiffre.\n",
    "\n",
    "Je vous propose dans cette section de construire un tel classifieur. Notre strat√©gie va consister √† r√©unir plusieurs classifieurs √† deux classes (que vous avez appris √† construire dans la section pr√©c√©dente) pour construire un classifieur √† 10 classes. \n",
    "Plus pr√©cis√©ment notre strat√©gie sera:\n",
    "\n",
    "- Couper le jeu de donn√©es en deux classes : les 0 et le reste (1, ..., 9). On produit alors un classifieur qui sera capable de savoir si une image est un z√©ro, ou non.\n",
    "- On refait la m√™me chose en isolant cette fois 1 versus le reste (0,2, ..., 9). Et ainsi de suite. Ce qui nous donnera 10 classifieurs, chacun r√©pondant √† la question \"est-ce que cette image est un 0? un 1? etc.\n",
    "- Etant donn√© une nouvelle image, on la passe dans les 10 classifieurs, et en fonction des 10 pr√©dictions on prend une d√©cision.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### b. Manipulation des donn√©es et construction du premier classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "from scipy.optimize import LinearConstraint, minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "plt.rcParams['xtick.labelbottom'] = True\n",
    "plt.rcParams['ytick.labelleft'] = True\n",
    "plt.rcParams['image.cmap'] = 'gray_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = sklearn.datasets.load_digits() # Importe un jeu de donn√©es √† classer (10 classes)\n",
    "digits.data = digits.data*1/np.max(digits.data) # normalise : coeffs dans [0,1]\n",
    "X, X_test, Y, Y_test = sklearn.model_selection.train_test_split( # On coupe le jeu de donn√©es en deux\n",
    "                        digits.data, digits.target, train_size=0.25, shuffle=True)\n",
    "etiquettes_original = Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** D√©terminer `m` le nombre de donn√©es contenues dans `X`, et `n` la dimension de ces donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "n = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** V√©rifier que `Y` contient bien des √©tiquettes allant de 0 √† 9. Dans le but de classer les 0 vs. le reste, cr√©ez un nouveau vecteur d'√©tiquettes `Y_temp` qui vaut +1 pour les 0, et -1 pour le reste. Faites bien attention √† ne pas modifier le `Y` original!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 vs le reste\n",
    "cible = 0\n",
    "Y_temp = np.where(etiquettes_original==cible, 1, -1) # Transforme 'cible' en +1, le reste en -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** En vous inspirant de ce que vous avez fait √† la section pr√©c√©dente:\n",
    "\n",
    "- d√©finissez le probl√®me de SVM associ√© au probl√®me de classifier 0 vs. le reste\n",
    "- r√©solvez-le, afin d'obtenir `w` un vecteur de param√®tres d√©finissant un hyperplan qui s√©pare les 0 des autres chiffres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Prenez quelques examples dans `X` et v√©rifiez que `w` d√©finit un hyperplan qui s√©pare bien les 0 du reste (cf. section pr√©c√©dente). Rappelez-vous que les vraies √©tiquettes sont contenues dans `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### c. Construction d'un classifieur g√©n√©ral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Ici vous devrez reproduire ce que vous venez de faire :\n",
    "\n",
    "- Pour chaque chiffre 'cible' entre 0 et 9:\n",
    "  - D√©finir un vecteur d'√©tiquettes d√©crivant un probl√®me de classification 'cible' vs. le reste\n",
    "  - D√©finir le probl√®me SVM associ√© et le r√©soudre, ce qui vous donnera un vecteurs de param√®tres w\n",
    "  - Ranger chacun de ces vecteurs $w \\in \\mathbb{R}^{n+1}$ comme ligne d'une matrice $W \\in \\mathcal{M}_{10, n+1}(\\mathbb{R})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** V√©rifiez que la matrice `W` obtenue donne de bons r√©sultats. Pour cela, pous pourrez prendre une image quelconque, et la passer dans le classifieur binaire pour chaque ligne de `W` : il devrait renvoyer +1 seulement pour le bon indice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** D√©finir une fonction `classifieur_general` qui:\n",
    "\n",
    "- prend en entr√©e une donn√©e $x$ et une matrice de param√®tres  $W \\in \\mathcal{M}_{10, n+1}(\\mathbb{R})$\n",
    "- pour chaque chiffre `i` entre 0 et 9, utilise le classifieur binaire induit par `W[i,:]` pour d√©terminer si $x$ est √©gal √† `i` ou non\n",
    "- renvoie `i` si $x$ est √©gal √† `i`\n",
    "- pensez √† faire en sorte que la fonction renvoie toujours quelque chose\n",
    "\n",
    "Vous testerez sur un exemple que cela marche bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifieur_general(x, W):\n",
    "    # #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Appliquez votre `classifieur_general` aux donn√©es de test, comme au **II.3.1)**. Quel est le pourcentage de bonnes r√©ponses de votre classifieur? Que pensez-vous du r√©sultat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### d. Construction d'un classifieur g√©n√©ral am√©lior√©\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le classifieur pr√©c√©dent souffre de quelques d√©fauts.\n",
    "Par exemple, si une image est class√©e comme appartenant √† deux classes, comment choisir laquelle des deux est la meilleure?\n",
    "Et si une image apparait class√©e comme appartenant √† aucune classe, comment choisir quelle classe est la moins mauvaise?\n",
    "On donc besoin que les classifieurs binaires renvoient un peu plus que une r√©ponse $\\pm 1$ pour chaque chiffre : il nous faut √©galement un indice de confiance, une *probabilit√©* que la r√©ponse $\\pm 1$ soit correcte.\n",
    "\n",
    "Par exemple, imaginons que le classifieur biniaire \"0 vs. le reste\" nous dise que $\\mathbb{P}(x=0) = 0.4$. Dans ce cas on pourrait conclure que $x$ n'est pas un 0, puisque $\\mathbb{P}(x\\neq 0) = 0.6$. Mais si tous les autres classifieurs binaires nous disent √©galement que $\\mathbb{P}(x=k) = 0.01$, alors on pourrait se dire que 0 est la moins mauvaise r√©ponse.\n",
    "\n",
    "Pour notre probl√®me, cette probabilit√© va √™tre li√©e √† la distance entre la donn√©e $x$ et l'hyperplan s√©parateur $H_w$ : plus la donn√©e est proche de l'hyperplan, et moins on aura confiance en la pr√©diction, donc plus basse sera la probabilit√©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** D√©finir une fonction `classifieur_general2` qui reprend le principe de `classifieur_general`. Cette fois-ci, l'indice `i` renvoy√© sera celui qui maximise la probabilit√© $p_i$, o√π $p \\in \\mathbb{R}^{10}$ est d√©fini par :\n",
    "\n",
    "$$ p_i := \\frac{e^{v_i}}{\\sum\\limits_{j=1}^p e^{v_j}},\n",
    "\\quad\n",
    "v_i := \\langle a^i, x \\rangle + b^i\n",
    "$$\n",
    "avec `W[i,:]`$=(a^i, b^i)$. \n",
    "Vous testerez sur un exemple que votre fonction marche bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Estimer la performance de votre nouveau classifieur sur les donn√©es de test. Comparer avec le classifieur pr√©c√©dent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour aller plus loin:** \n",
    "\n",
    "- Rien ne vous emp√™che de dessiner vos propres chiffres, et de tester si votre classifieur le reconnait.. Pour cela il vous suffit de produire une image carr√©e, de la redimensionner en image 8x8, puis de l'importer dans python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "Ressources utilis√©es pour le chargment et utilisation de MNIST:\n",
    "\n",
    "- https://dmkothari.github.io/Machine-Learning-Projects/SVM_with_MNIST.html\n",
    "- https://towardsdatascience.com/support-vector-machine-mnist-digit-classification-with-python-including-my-hand-written-digits-83d6eca7004a\n",
    "- https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
